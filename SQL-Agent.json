{"id":"8b3a28c6-3332-48d0-9aed-7c624d228570","data":{"nodes":[{"id":"SQLAgent-Plwpd","type":"genericNode","position":{"x":575.2587543496461,"y":144.87887011175212},"data":{"type":"SQLAgent","node":{"template":{"llm":{"type":"BaseLanguageModel","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"llm","display_name":"LLM","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Callable, Union\n\nfrom langchain.agents import AgentExecutor\nfrom langchain_community.agent_toolkits import SQLDatabaseToolkit\nfrom langchain_community.agent_toolkits.sql.base import create_sql_agent\nfrom langchain_community.utilities import SQLDatabase\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseLanguageModel\n\n\nclass SQLAgentComponent(CustomComponent):\n    display_name = \"SQLAgent\"\n    description = \"Construct an SQL agent from an LLM and tools.\"\n\n    def build_config(self):\n        return {\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"database_uri\": {\"display_name\": \"Database URI\"},\n            \"verbose\": {\"display_name\": \"Verbose\", \"value\": False, \"advanced\": True},\n        }\n\n    def build(\n        self,\n        llm: BaseLanguageModel,\n        database_uri: str,\n        verbose: bool = False,\n    ) -> Union[AgentExecutor, Callable]:\n        db = SQLDatabase.from_uri(database_uri)\n        toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n        return create_sql_agent(llm=llm, toolkit=toolkit, handle_parsing_errors=True)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"database_uri":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"database_uri","display_name":"Database URI","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"verbose":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"verbose","display_name":"Verbose","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Construct an SQL agent from an LLM and tools.","base_classes":["AgentExecutor","Callable","Chain","Generic","object","Runnable","RunnableSerializable","Serializable"],"display_name":"SQLAgent","documentation":"","custom_fields":{"llm":null,"database_uri":null,"verbose":null},"output_types":["AgentExecutor","Callable"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"SQLAgent-Plwpd","description":"Construct an SQL agent from an LLM and tools.","display_name":"SQLAgent"},"selected":false,"width":384,"height":337,"positionAbsolute":{"x":575.2587543496461,"y":144.87887011175212},"dragging":false},{"id":"ChatOpenAISpecs-1O9xT","type":"genericNode","position":{"x":84.1811295497854,"y":55.35492234789939},"data":{"type":"ChatOpenAISpecs","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import BaseLanguageModel, NestedDict\n\n\nclass ChatOpenAIComponent(CustomComponent):\n    display_name = \"ChatOpenAI\"\n    description = \"`OpenAI` Chat large language models API.\"\n    icon = \"OpenAI\"\n\n    def build_config(self):\n        return {\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"advanced\": True,\n                \"required\": False,\n            },\n            \"model_name\": {\"display_name\": \"Model Name\", \"advanced\": False, \"options\": MODEL_NAMES},\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"advanced\": False,\n                \"required\": False,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"advanced\": False,\n                \"required\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"advanced\": False,\n                \"required\": False,\n                \"value\": 0.7,\n            },\n        }\n\n    def build(\n        self,\n        max_tokens: Optional[int] = 0,\n        model_kwargs: NestedDict = {},\n        model_name: str = \"gpt-4o\",\n        openai_api_base: Optional[str] = None,\n        openai_api_key: Optional[str] = None,\n        temperature: float = 0.7,\n    ) -> BaseLanguageModel:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        return ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","load_from_db":false,"title_case":false},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"gpt-4-turbo","fileTypes":[],"file_path":"","password":false,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":false,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"openai_api_key":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.7,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"`OpenAI` Chat large language models API.","icon":"OpenAI","base_classes":["BaseLanguageModel","Generic","object","Runnable","RunnableSerializable","Serializable"],"display_name":"ChatOpenAI","documentation":"","custom_fields":{"max_tokens":null,"model_kwargs":null,"model_name":null,"openai_api_base":null,"openai_api_key":null,"temperature":null},"output_types":["BaseLanguageModel"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatOpenAISpecs-1O9xT"},"selected":false,"width":384,"height":563,"positionAbsolute":{"x":84.1811295497854,"y":55.35492234789939},"dragging":false},{"id":"RunnableExecutor-zrfRk","type":"genericNode","position":{"x":1071.9154830183197,"y":-22.219580371703586},"data":{"type":"RunnableExecutor","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Inputs","advanced":false,"dynamic":false,"info":"The inputs to pass to the runnable.","load_from_db":false,"title_case":false,"input_types":["Text"]},"runnable":{"type":"Runnable","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"runnable","display_name":"Runnable","advanced":false,"input_types":["Chain","AgentExecutor","Agent","Runnable"],"dynamic":false,"info":"The runnable to execute.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.runnables import Runnable\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Text\n\n\nclass RunnableExecComponent(CustomComponent):\n    description = \"Execute a runnable. It will try to guess the input and output keys.\"\n    display_name = \"Runnable Executor\"\n    beta: bool = True\n    field_order = [\n        \"input_key\",\n        \"output_key\",\n        \"input_value\",\n        \"runnable\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_key\": {\n                \"display_name\": \"Input Key\",\n                \"info\": \"The key to use for the input.\",\n                \"advanced\": True,\n            },\n            \"input_value\": {\n                \"display_name\": \"Inputs\",\n                \"info\": \"The inputs to pass to the runnable.\",\n            },\n            \"runnable\": {\n                \"display_name\": \"Runnable\",\n                \"info\": \"The runnable to execute.\",\n                \"input_types\": [\"Chain\", \"AgentExecutor\", \"Agent\", \"Runnable\"],\n            },\n            \"output_key\": {\n                \"display_name\": \"Output Key\",\n                \"info\": \"The key to use for the output.\",\n                \"advanced\": True,\n            },\n        }\n\n    def get_output(self, result, input_key, output_key):\n        \"\"\"\n        Retrieves the output value from the given result dictionary based on the specified input and output keys.\n\n        Args:\n            result (dict): The result dictionary containing the output value.\n            input_key (str): The key used to retrieve the input value from the result dictionary.\n            output_key (str): The key used to retrieve the output value from the result dictionary.\n\n        Returns:\n            tuple: A tuple containing the output value and the status message.\n\n        \"\"\"\n        possible_output_keys = [\"answer\", \"response\", \"output\", \"result\", \"text\"]\n        status = \"\"\n        result_value = None\n\n        if output_key in result:\n            result_value = result.get(output_key)\n        elif len(result) == 2 and input_key in result:\n            # get the other key from the result dict\n            other_key = [k for k in result if k != input_key][0]\n            if other_key == output_key:\n                result_value = result.get(output_key)\n            else:\n                status += f\"Warning: The output key is not '{output_key}'. The output key is '{other_key}'.\"\n                result_value = result.get(other_key)\n        elif len(result) == 1:\n            result_value = list(result.values())[0]\n        elif any(k in result for k in possible_output_keys):\n            for key in possible_output_keys:\n                if key in result:\n                    result_value = result.get(key)\n                    status += f\"Output key: '{key}'.\"\n                    break\n            if result_value is None:\n                result_value = result\n                status += f\"Warning: The output key is not '{output_key}'.\"\n        else:\n            result_value = result\n            status += f\"Warning: The output key is not '{output_key}'.\"\n\n        return result_value, status\n\n    def get_input_dict(self, runnable, input_key, input_value):\n        \"\"\"\n        Returns a dictionary containing the input key-value pair for the given runnable.\n\n        Args:\n            runnable: The runnable object.\n            input_key: The key for the input value.\n            input_value: The value for the input key.\n\n        Returns:\n            input_dict: A dictionary containing the input key-value pair.\n            status: A status message indicating if the input key is not in the runnable's input keys.\n        \"\"\"\n        input_dict = {}\n        status = \"\"\n        if hasattr(runnable, \"input_keys\"):\n            # Check if input_key is in the runnable's input_keys\n            if input_key in runnable.input_keys:\n                input_dict[input_key] = input_value\n            else:\n                input_dict = {k: input_value for k in runnable.input_keys}\n                status = f\"Warning: The input key is not '{input_key}'. The input key is '{runnable.input_keys}'.\"\n        return input_dict, status\n\n    def build(\n        self,\n        input_value: Text,\n        runnable: Runnable,\n        input_key: str = \"input\",\n        output_key: str = \"output\",\n    ) -> Text:\n        input_dict, status = self.get_input_dict(runnable, input_key, input_value)\n        result = runnable.invoke(input_dict)\n        result_value, _status = self.get_output(result, input_key, output_key)\n        status += _status\n        status += f\"\\n\\nOutput: {result_value}\\n\\nRaw Output: {result}\"\n        self.status = status\n        return result_value\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_key":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"input","fileTypes":[],"file_path":"","password":false,"name":"input_key","display_name":"Input Key","advanced":true,"dynamic":false,"info":"The key to use for the input.","load_from_db":false,"title_case":false,"input_types":["Text"]},"output_key":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"output","fileTypes":[],"file_path":"","password":false,"name":"output_key","display_name":"Output Key","advanced":true,"dynamic":false,"info":"The key to use for the output.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Execute a runnable. It will try to guess the input and output keys.","base_classes":["object","str","Text"],"display_name":"Runnable Executor","documentation":"","custom_fields":{"input_value":null,"runnable":null,"input_key":null,"output_key":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["input_key","output_key","input_value","runnable"],"beta":true},"id":"RunnableExecutor-zrfRk"},"selected":false,"width":384,"height":357,"positionAbsolute":{"x":1071.9154830183197,"y":-22.219580371703586},"dragging":false},{"id":"ChatInput-FBpD0","type":"genericNode","position":{"x":567.2155510759317,"y":-316.2698603507239},"data":{"type":"ChatInput","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Message\",\n            \"multiline\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n    ) -> Union[Text, Record]:\n        return super().build_no_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Message","advanced":false,"input_types":[],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"value":"what is the returned capital for management"},"return_record":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_record","display_name":"Return Record","advanced":true,"dynamic":false,"info":"Return the message as a record containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["object","Record","str","Text"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"return_record":null},"output_types":["Text","Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatInput-FBpD0"},"selected":false,"width":384,"height":375,"positionAbsolute":{"x":567.2155510759317,"y":-316.2698603507239},"dragging":false},{"id":"ChatOutput-WY1T8","type":"genericNode","position":{"x":1574.7484960310762,"y":180.10144026774702},"data":{"type":"ChatOutput","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n        record_template: Optional[str] = \"{text}\",\n    ) -> Union[Text, Record]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n            record_template=record_template or \"\",\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Message","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"{text}","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"In case of Message being a Record, this template will be used to convert it to text.","load_from_db":false,"title_case":false,"input_types":["Text"]},"return_record":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_record","display_name":"Return Record","advanced":true,"dynamic":false,"info":"Return the message as a record containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":true,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["object","Record","str","Text"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"return_record":null,"record_template":null},"output_types":["Text","Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"ChatOutput-WY1T8"},"selected":false,"width":384,"height":383,"positionAbsolute":{"x":1574.7484960310762,"y":180.10144026774702},"dragging":false},{"id":"CustomComponent-NxwPt","type":"genericNode","position":{"x":-471.8018631672112,"y":-200.82722300386723},"data":{"type":"CustomComponent","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Prompt, TemplateField, Text\nfrom sqlalchemy_utils import database_exists, create_database\n\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\n\nclass SQLDBComponent(CustomComponent):\n    display_name = \"SQLDBComponent\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n\n    def build_config(self):\n        return {\n            \"user\": {\"display_name\": \"user\"},\n            \"password\": {\"display_name\": \"password\"},\n            \"host\": {\"display_name\": \"host\"},\n            \"database\": {\"display_name\": \"database\"},\n            \"files\": {\"display_name\": \"files\"},\n            \n        }\n        \n\n    def build(self, user:str, password: str, host: str, database : str, files : str) -> str:\n        # Read the CSV file\n        files = files.split('|')\n        \n        # user = 'root'\n        # password = 'test'\n        # host = 'localhost'  \n        # database = 'dbname'\n        \n        uri = f'mysql+mysqlconnector://{user}:{password}@{host}/{database}'\n        engine = create_engine(uri)\n        \n        if not database_exists(engine.url):\n            create_database(engine.url)\n        \n        for file in files:\n            df = pd.read_csv(file)\n            df.to_sql(file.split('.')[0].upper(), con=engine, if_exists='replace', index=False)\n        \n        return uri\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"database":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"database","display_name":"database","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"gsheetDB"},"files":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"files","display_name":"files","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"host":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"host","display_name":"host","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"localhost"},"password":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"password","display_name":"password","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"user":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"user","display_name":"user","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"_type":"CustomComponent"},"description":"Use as a template to create your own component.","icon":"custom_components","base_classes":["object","str","Text"],"display_name":"SQLDatabaseCreate","documentation":"http://docs.langflow.org/components/custom","custom_fields":{"user":null,"password":null,"host":null,"database":null,"files":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"CustomComponent-NxwPt","description":"Use as a template to create your own component.","display_name":"SQLDatabaseCreate"},"selected":false,"width":384,"height":663,"dragging":false,"positionAbsolute":{"x":-471.8018631672112,"y":-200.82722300386723}},{"id":"Prompt-qIza7","type":"genericNode","position":{"x":-2088.0665512845294,"y":-564.2984460274743},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.prompts import PromptTemplate\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Prompt, TemplateField, Text\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from langflow.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"Using the below content, you have to extract all the tables from the unstructured excel sheet. Each table should have column headers and a title. \n\nIMPORTANT - Carefully infer the column headers. Do not use the table cell values as the column headers. Headers cannot be numbers. If the column header is missing, use an appropriate word for the header. \n\nDo not skip any data points, include them all in the tables. For missing values, write NaN. Do not give any introductory meta-text, only the output. Do not add any extra spaces, newlines, or formatting. The output should be strictly in the following format:\n\nTable 1 - Users\nUsername,Identifier,First name,Last name\nbooker12,9012,Rachel,Booker\ngrey07,2070,Laura,Grey\njohnson81,4081,Craig,Johnson\njenkins46,9346,Mary,Jenkins\nsmith79,5079,Jamie,Smith\n\nTable 2 - Ages\nUsername,Age\nbooker12,12\ngrey07,34\njohnson81,56\njenkins46,17\nsmith79,13\n\nHere is the content:\n\n{content}","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","content":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"content","display_name":"content","advanced":false,"input_types":["Document","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["object","str","Text"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["content"]},"output_types":["Text"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-qIza7","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":381,"dragging":false,"positionAbsolute":{"x":-2088.0665512845294,"y":-564.2984460274743}},{"id":"OpenAIModel-87pha","type":"genericNode","position":{"x":-1526.7017389394875,"y":-862.8319198677539},"data":{"type":"OpenAIModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import NestedDict, Text\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n\n    field_order = [\n        \"max_tokens\",\n        \"model_kwargs\",\n        \"model_name\",\n        \"openai_api_base\",\n        \"openai_api_key\",\n        \"temperature\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"advanced\": False,\n                \"options\": MODEL_NAMES,\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"advanced\": True,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"info\": \"The OpenAI API Key to use for the OpenAI model.\",\n                \"advanced\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"advanced\": False,\n                \"value\": 0.1,\n            },\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        openai_api_key: str,\n        temperature: float,\n        model_name: str = \"gpt-4o\",\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature,\n        )\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"2048","fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":false,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","load_from_db":false,"title_case":false},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"gpt-4o","fileTypes":[],"file_path":"","password":false,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"0.0","fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["object","str","Text"],"display_name":"OpenAI","documentation":"","custom_fields":{"input_value":null,"openai_api_key":null,"temperature":null,"model_name":null,"max_tokens":null,"model_kwargs":null,"openai_api_base":null,"stream":null,"system_message":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["max_tokens","model_kwargs","model_name","openai_api_base","openai_api_key","temperature","input_value","system_message","stream"],"beta":false},"id":"OpenAIModel-87pha"},"selected":false,"width":384,"height":647,"positionAbsolute":{"x":-1526.7017389394875,"y":-862.8319198677539},"dragging":false},{"id":"CustomComponent-YekEH","type":"genericNode","position":{"x":-970.4123595515979,"y":-155.94762063867827},"data":{"type":"CustomComponent","node":{"template":{"content":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"content","display_name":"tables content","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"content2":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"content2","display_name":"tables content","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\nfrom langflow.field_typing import Prompt, TemplateField, Text\n\nimport pandas as pd\nimport re\n\nclass TableParser(CustomComponent):\n    display_name = \"TableParser\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n\n    def build_config(self):\n        return {\"content\": {\"display_name\": \"tables content\"},\n                \"content2\": {\"display_name\": \"tables content\"},\n        }\n\n    def build(self, content : Text, content2 : Text) -> str:\n        \n        f = open(\"log1.txt\", \"w\")\n        f.write(content)\n        f.close()\n        \n        f = open(\"log2.txt\", \"w\")\n        f.write(content2)\n        f.close()\n        \n        content = content.split('\\n')\n        content2 = content2.split('\\n')\n        \n        content = content + content2\n        \n        current_table = None\n        table_data = []\n        fnames = []\n        \n        \n        for line in content:\n            line = line.strip()\n        \n            \n            if line.startswith('Table'):\n                \n                if current_table and table_data:\n                    df = pd.DataFrame(table_data[1:], columns=table_data[0])\n                    df = df.replace('NaN', pd.NA)\n                    numeric_columns = df.columns[df.dtypes == object].tolist()\n                    # df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='ignore')\n                    filename = current_table.replace(' ', '_').lower() + '.csv'\n                    df.to_csv(filename, index=False)\n                    fnames.append(filename)\n                    current_table = None\n                    table_data = []\n        \n                current_table = line[10:]\n          \n            elif ',' in line:\n                table_data.append([item.strip() for item in line.split(',')])\n            \n        \n        if current_table and table_data:\n            df = pd.DataFrame(table_data[1:], columns=table_data[0])\n            df = df.replace('NaN', pd.NA)\n            numeric_columns = df.columns[df.dtypes == object].tolist()\n            df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='ignore')\n            filename = current_table.replace(' ', '_').lower() + '.csv'\n            df.to_csv(filename, index=False)\n            fnames.append(filename)\n\n        return \"|\".join(fnames)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Use as a template to create your own component.","icon":"custom_components","base_classes":["object","str","Text"],"display_name":"TableParser","documentation":"http://docs.langflow.org/components/custom","custom_fields":{"content":null,"content2":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"CustomComponent-YekEH","description":"Use as a template to create your own component.","display_name":"TableParser"},"selected":false,"width":384,"height":381,"dragging":false,"positionAbsolute":{"x":-970.4123595515979,"y":-155.94762063867827}},{"id":"CustomComponent-Fsm7O","type":"genericNode","position":{"x":-2625.1863941923857,"y":-421.4812113755882},"data":{"type":"CustomComponent","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\nimport openpyxl\nimport csv\n\nclass XLSXComponent(CustomComponent):\n    display_name = \"XLSXComponent\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n\n    def build_config(self):\n        return {\n            \"path\": {\n                \"display_name\": \"Path\",\n            },\n        }\n        \n    def load_file(self, path: str, silent_errors: bool = False) -> Record:\n        resolved_path = self.resolve_path(path)\n        path_obj = Path(resolved_path)\n        extension = path_obj.suffix[1:].lower()\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n        record = parse_text_file_to_record(resolved_path, silent_errors)\n        self.status = record if record else \"No data\"\n        return record or Record()\n\n    def build(self, path :str) -> str:\n        workbook = openpyxl.load_workbook(path, data_only=True)\n        \n        records = []\n\n        for worksheet, name in zip(workbook.worksheets,workbook.sheetnames):\n            with open(f'{name}.csv', 'w', newline='', encoding='utf-8') as csvfile:\n                csv_writer = csv.writer(csvfile, delimiter='|')\n                for row in worksheet.iter_rows(values_only=True):\n                    wrow = ['\\t' if cell is None else cell for cell in row]\n                    while wrow and wrow[-1] == '\\t':\n                        wrow.pop()\n                    csv_writer.writerow(wrow)\n                \n            records.append(self.load_file(f'{name}.csv'))\n            \n    \n        return records[0]\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"path":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"path","display_name":"Path","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"_type":"CustomComponent"},"description":"Use as a template to create your own component.","icon":"custom_components","base_classes":["object","str","Text"],"display_name":"XLSXComponent","documentation":"http://docs.langflow.org/components/custom","custom_fields":{"path":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"CustomComponent-Fsm7O","description":"Use as a template to create your own component.","display_name":"XLSXComponent"},"selected":false,"width":384,"height":287,"positionAbsolute":{"x":-2625.1863941923857,"y":-421.4812113755882},"dragging":false},{"id":"Prompt-efNz9","type":"genericNode","position":{"x":-2085.4151184044704,"y":-45.34500435005057},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.prompts import PromptTemplate\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Prompt, TemplateField, Text\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from langflow.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"Using the below content, you have to extract all the tables from the unstructured excel sheet. Each table should have column headers and a title. \n\nIMPORTANT - Carefully infer the column headers. Do not use the table cell values as the column headers. Headers cannot be numbers. If the column header is missing, use an appropriate word for the header. \n\nDo not skip any data points, include them all in the tables. For missing values, write NaN. Do not give any introductory meta-text, only the output. Do not add any extra spaces, newlines, or formatting. The output should be strictly in the following format:\n\n\nTable 1 - Users\nUsername,Identifier,First name,Last name\nbooker12,9012,Rachel,Booker\ngrey07,2070,Laura,Grey\njohnson81,4081,Craig,Johnson\njenkins46,9346,Mary,Jenkins\nsmith79,5079,Jamie,Smith\n\nTable 2 - Ages\nUsername,Age\nbooker12,12\ngrey07,34\njohnson81,56\njenkins46,17\nsmith79,13\n\nHere is the content:\n\n{content}","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","content":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"content","display_name":"content","advanced":false,"input_types":["Document","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["object","str","Text"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["content"]},"output_types":["Text"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-efNz9","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":381,"positionAbsolute":{"x":-2085.4151184044704,"y":-45.34500435005057},"dragging":false},{"id":"OpenAIModel-0U1O0","type":"genericNode","position":{"x":-1504.7961880578405,"y":-74.41908518477322},"data":{"type":"OpenAIModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import NestedDict, Text\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n\n    field_order = [\n        \"max_tokens\",\n        \"model_kwargs\",\n        \"model_name\",\n        \"openai_api_base\",\n        \"openai_api_key\",\n        \"temperature\",\n        \"input_value\",\n        \"system_message\",\n        \"stream\",\n    ]\n\n    def build_config(self):\n        return {\n            \"input_value\": {\"display_name\": \"Input\"},\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"advanced\": True,\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            },\n            \"model_kwargs\": {\n                \"display_name\": \"Model Kwargs\",\n                \"advanced\": True,\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"advanced\": False,\n                \"options\": MODEL_NAMES,\n            },\n            \"openai_api_base\": {\n                \"display_name\": \"OpenAI API Base\",\n                \"advanced\": True,\n                \"info\": (\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\n                ),\n            },\n            \"openai_api_key\": {\n                \"display_name\": \"OpenAI API Key\",\n                \"info\": \"The OpenAI API Key to use for the OpenAI model.\",\n                \"advanced\": False,\n                \"password\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"advanced\": False,\n                \"value\": 0.1,\n            },\n            \"stream\": {\n                \"display_name\": \"Stream\",\n                \"info\": STREAM_INFO_TEXT,\n                \"advanced\": True,\n            },\n            \"system_message\": {\n                \"display_name\": \"System Message\",\n                \"info\": \"System message to pass to the model.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        input_value: Text,\n        openai_api_key: str,\n        temperature: float,\n        model_name: str = \"gpt-4o\",\n        max_tokens: Optional[int] = 256,\n        model_kwargs: NestedDict = {},\n        openai_api_base: Optional[str] = None,\n        stream: bool = False,\n        system_message: Optional[str] = None,\n    ) -> Text:\n        if not openai_api_base:\n            openai_api_base = \"https://api.openai.com/v1\"\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature,\n        )\n\n        return self.get_chat_result(output, stream, input_value, system_message)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"2048","fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":false,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","load_from_db":false,"title_case":false},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"gpt-4o","fileTypes":[],"file_path":"","password":false,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"0.0","fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["object","str","Text"],"display_name":"OpenAI","documentation":"","custom_fields":{"input_value":null,"openai_api_key":null,"temperature":null,"model_name":null,"max_tokens":null,"model_kwargs":null,"openai_api_base":null,"stream":null,"system_message":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["max_tokens","model_kwargs","model_name","openai_api_base","openai_api_key","temperature","input_value","system_message","stream"],"beta":false},"id":"OpenAIModel-0U1O0"},"selected":false,"width":384,"height":647,"positionAbsolute":{"x":-1504.7961880578405,"y":-74.41908518477322},"dragging":false},{"id":"CustomComponent-xHA88","type":"genericNode","position":{"x":-2628.1869770139083,"y":-73.28701622873025},"data":{"type":"CustomComponent","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\nfrom langflow.custom import CustomComponent\nfrom langflow.schema import Record\nimport openpyxl\nimport csv\n\nclass XLSXComponent(CustomComponent):\n    display_name = \"XLSXComponent\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"custom_components\"\n\n    def build_config(self):\n        return {\n            \"path\": {\n                \"display_name\": \"Path\",\n            },\n        }\n        \n    def load_file(self, path: str, silent_errors: bool = False) -> Record:\n        resolved_path = self.resolve_path(path)\n        path_obj = Path(resolved_path)\n        extension = path_obj.suffix[1:].lower()\n        if extension == \"doc\":\n            raise ValueError(\"doc files are not supported. Please save as .docx\")\n        if extension not in TEXT_FILE_TYPES:\n            raise ValueError(f\"Unsupported file type: {extension}\")\n        record = parse_text_file_to_record(resolved_path, silent_errors)\n        self.status = record if record else \"No data\"\n        return record or Record()\n\n    def build(self, path :str) -> str:\n        workbook = openpyxl.load_workbook(path, data_only=True)\n        \n        records = []\n\n        for worksheet, name in zip(workbook.worksheets,workbook.sheetnames):\n            with open(f'{name}.csv', 'w', newline='', encoding='utf-8') as csvfile:\n                csv_writer = csv.writer(csvfile, delimiter='|')\n                for row in worksheet.iter_rows(values_only=True):\n                    wrow = ['\\t' if cell is None else cell for cell in row]\n                    while wrow and wrow[-1] == '\\t':\n                        wrow.pop()\n                    csv_writer.writerow(wrow)\n                \n            records.append(self.load_file(f'{name}.csv'))\n            \n    \n        return records[1]\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"path":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"path","display_name":"Path","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"_type":"CustomComponent"},"description":"Use as a template to create your own component.","icon":"custom_components","base_classes":["object","str","Text"],"display_name":"XLSXComponent","documentation":"http://docs.langflow.org/components/custom","custom_fields":{"path":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false},"id":"CustomComponent-xHA88","description":"Use as a template to create your own component.","display_name":"XLSXComponent"},"selected":false,"width":384,"height":287,"positionAbsolute":{"x":-2628.1869770139083,"y":-73.28701622873025},"dragging":false}],"edges":[{"source":"ChatOpenAISpecs-1O9xT","sourceHandle":"{œbaseClassesœ:[œBaseLanguageModelœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œChatOpenAISpecsœ,œidœ:œChatOpenAISpecs-1O9xTœ}","target":"SQLAgent-Plwpd","targetHandle":"{œfieldNameœ:œllmœ,œidœ:œSQLAgent-Plwpdœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}","data":{"targetHandle":{"fieldName":"llm","id":"SQLAgent-Plwpd","inputTypes":null,"type":"BaseLanguageModel"},"sourceHandle":{"baseClasses":["BaseLanguageModel","Generic","object","Runnable","RunnableSerializable","Serializable"],"dataType":"ChatOpenAISpecs","id":"ChatOpenAISpecs-1O9xT"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-ChatOpenAISpecs-1O9xT{œbaseClassesœ:[œBaseLanguageModelœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œChatOpenAISpecsœ,œidœ:œChatOpenAISpecs-1O9xTœ}-SQLAgent-Plwpd{œfieldNameœ:œllmœ,œidœ:œSQLAgent-Plwpdœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"},{"source":"SQLAgent-Plwpd","sourceHandle":"{œbaseClassesœ:[œAgentExecutorœ,œCallableœ,œChainœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œSQLAgentœ,œidœ:œSQLAgent-Plwpdœ}","target":"RunnableExecutor-zrfRk","targetHandle":"{œfieldNameœ:œrunnableœ,œidœ:œRunnableExecutor-zrfRkœ,œinputTypesœ:[œChainœ,œAgentExecutorœ,œAgentœ,œRunnableœ],œtypeœ:œRunnableœ}","data":{"targetHandle":{"fieldName":"runnable","id":"RunnableExecutor-zrfRk","inputTypes":["Chain","AgentExecutor","Agent","Runnable"],"type":"Runnable"},"sourceHandle":{"baseClasses":["AgentExecutor","Callable","Chain","Generic","object","Runnable","RunnableSerializable","Serializable"],"dataType":"SQLAgent","id":"SQLAgent-Plwpd"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-SQLAgent-Plwpd{œbaseClassesœ:[œAgentExecutorœ,œCallableœ,œChainœ,œGenericœ,œobjectœ,œRunnableœ,œRunnableSerializableœ,œSerializableœ],œdataTypeœ:œSQLAgentœ,œidœ:œSQLAgent-Plwpdœ}-RunnableExecutor-zrfRk{œfieldNameœ:œrunnableœ,œidœ:œRunnableExecutor-zrfRkœ,œinputTypesœ:[œChainœ,œAgentExecutorœ,œAgentœ,œRunnableœ],œtypeœ:œRunnableœ}"},{"source":"ChatInput-FBpD0","sourceHandle":"{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-FBpD0œ}","target":"RunnableExecutor-zrfRk","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œRunnableExecutor-zrfRkœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"RunnableExecutor-zrfRk","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","Record","str","Text"],"dataType":"ChatInput","id":"ChatInput-FBpD0"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-ChatInput-FBpD0{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-FBpD0œ}-RunnableExecutor-zrfRk{œfieldNameœ:œinput_valueœ,œidœ:œRunnableExecutor-zrfRkœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"RunnableExecutor-zrfRk","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œRunnableExecutorœ,œidœ:œRunnableExecutor-zrfRkœ}","target":"ChatOutput-WY1T8","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-WY1T8œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-WY1T8","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"RunnableExecutor","id":"RunnableExecutor-zrfRk"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-RunnableExecutor-zrfRk{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œRunnableExecutorœ,œidœ:œRunnableExecutor-zrfRkœ}-ChatOutput-WY1T8{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-WY1T8œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"Prompt-qIza7","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-qIza7œ}","target":"OpenAIModel-87pha","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-87phaœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-87pha","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"Prompt","id":"Prompt-qIza7"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-Prompt-qIza7{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-qIza7œ}-OpenAIModel-87pha{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-87phaœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"OpenAIModel-87pha","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-87phaœ}","target":"CustomComponent-YekEH","targetHandle":"{œfieldNameœ:œcontentœ,œidœ:œCustomComponent-YekEHœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"content","id":"CustomComponent-YekEH","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"OpenAIModel","id":"OpenAIModel-87pha"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-OpenAIModel-87pha{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-87phaœ}-CustomComponent-YekEH{œfieldNameœ:œcontentœ,œidœ:œCustomComponent-YekEHœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"CustomComponent-YekEH","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-YekEHœ}","target":"CustomComponent-NxwPt","targetHandle":"{œfieldNameœ:œfilesœ,œidœ:œCustomComponent-NxwPtœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"files","id":"CustomComponent-NxwPt","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"CustomComponent","id":"CustomComponent-YekEH"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-CustomComponent-YekEH{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-YekEHœ}-CustomComponent-NxwPt{œfieldNameœ:œfilesœ,œidœ:œCustomComponent-NxwPtœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","selected":false},{"source":"CustomComponent-Fsm7O","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Fsm7Oœ}","target":"Prompt-qIza7","targetHandle":"{œfieldNameœ:œcontentœ,œidœ:œPrompt-qIza7œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"content","id":"Prompt-qIza7","inputTypes":["Document","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"CustomComponent","id":"CustomComponent-Fsm7O"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-CustomComponent-Fsm7O{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-Fsm7Oœ}-Prompt-qIza7{œfieldNameœ:œcontentœ,œidœ:œPrompt-qIza7œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"},{"source":"Prompt-efNz9","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-efNz9œ}","target":"OpenAIModel-0U1O0","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-0U1O0œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-0U1O0","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"Prompt","id":"Prompt-efNz9"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-Prompt-efNz9{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-efNz9œ}-OpenAIModel-0U1O0{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-0U1O0œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"OpenAIModel-0U1O0","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-0U1O0œ}","target":"CustomComponent-YekEH","targetHandle":"{œfieldNameœ:œcontent2œ,œidœ:œCustomComponent-YekEHœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"content2","id":"CustomComponent-YekEH","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"OpenAIModel","id":"OpenAIModel-0U1O0"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-OpenAIModel-0U1O0{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-0U1O0œ}-CustomComponent-YekEH{œfieldNameœ:œcontent2œ,œidœ:œCustomComponent-YekEHœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"CustomComponent-xHA88","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-xHA88œ}","target":"Prompt-efNz9","targetHandle":"{œfieldNameœ:œcontentœ,œidœ:œPrompt-efNz9œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"content","id":"Prompt-efNz9","inputTypes":["Document","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"CustomComponent","id":"CustomComponent-xHA88"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-CustomComponent-xHA88{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-xHA88œ}-Prompt-efNz9{œfieldNameœ:œcontentœ,œidœ:œPrompt-efNz9œ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"}],"viewport":{"x":264.1079366143389,"y":122.68020471647333,"zoom":0.5774315613254932}},"description":"SQL Agent","name":"SQL-Agent","last_tested_version":"1.0.0a42","is_component":false}